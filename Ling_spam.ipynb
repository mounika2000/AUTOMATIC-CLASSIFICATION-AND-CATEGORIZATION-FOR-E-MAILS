{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary can be seen by the command print dictionary. You may find some absurd word counts to be high but itâ€™s just a dictionary and you always have the scope of  improving it later.\n",
    "def make_Dictionary(train_dir):\n",
    "    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]    \n",
    "    all_words = []       \n",
    "    for mail in emails:    \n",
    "        with open(mail) as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    all_words += words\n",
    "    \n",
    "    dictionary = Counter(all_words)\n",
    "    \n",
    "    list_to_remove = list(dictionary.keys())\n",
    "    for item in list_to_remove:\n",
    "        if item.isalpha() == False: \n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each word count vector contains the frequency of words in the training file. \n",
    "def extract_features(mail_dir): \n",
    "    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "    features_matrix = np.zeros((len(files),3000))\n",
    "    docID = 0;\n",
    "    for fil in files:\n",
    "      with open(fil) as fi:\n",
    "        for i,line in enumerate(fi):\n",
    "          if i == 2:\n",
    "            words = line.split()\n",
    "            for word in words:\n",
    "              wordID = 0\n",
    "              for i,d in enumerate(dictionary):\n",
    "                if d[0] == word:\n",
    "                  wordID = i\n",
    "                  features_matrix[docID,wordID] = words.count(word)\n",
    "        docID = docID + 1     \n",
    "    return features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of words with its frequency\n",
    "# directory \n",
    "train_dir = 'E:\\\\data\\\\ling-spam\\\\train-mails'\n",
    "dictionary = make_Dictionary(train_dir)\n",
    "\n",
    "# Prepare feature vectors per training mail and its labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.zeros(702)\n",
    "train_labels[351:701] = 1\n",
    "train_matrix = extract_features(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier is a conventional and very popular method for document classification problem. It is a supervised probabilistic classifier based on Bayes theorem assuming independence between every pair of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMs are supervised binary classifiers which are very effective when you have higher number of features. The goal of SVM is to separate some subset of training data from rest called the support vectors (boundary of separating hyper-plane). The decision function of SVM model that predicts the class of the test data is based on support vectors and makes use of a kernel trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Training SVM and Naive bayes classifier and its variants\n",
    "\n",
    "model1 = LinearSVC()\n",
    "\n",
    "model1.fit(train_matrix,train_labels)\n",
    "\n",
    "# Test the unseen mails for Spam\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MultinomialNB()\n",
    "model2.fit(train_matrix,train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the classifiers are trained, we can check the performance of the models on test-set. We extract word count vector for each mail in test-set and predict its class(ham or spam) with the trained NB classifier and SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'E:\\\\data\\\\ling-spam\\\\test'\n",
    "test_matrix = extract_features(test_dir)\n",
    "test_labels = np.zeros(360)\n",
    "test_labels[230:360] = 1\n",
    "\n",
    "result1 = model1.predict(test_matrix)\n",
    "result2 = model2.predict(test_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_matrix,train_labels)\n",
    "# Output of the score is the accuracy of the prediction\n",
    "# Accuracy: 0.995\n",
    "x3=clf.score(train_matrix,train_labels)\n",
    "print('Accuracy:',x3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC model-  1.0\n",
      "Multinomial Naive Bayes-  0.9886039886039886\n",
      "Gaussian Naive Bayes-  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "x1=model1.score(train_matrix,train_labels)\n",
    "x2=model2.score(train_matrix,train_labels)\n",
    "x3=clf.score(train_matrix,train_labels)\n",
    "print('Linear SVC model- ',x1)\n",
    "print('Multinomial Naive Bayes- ',x2)\n",
    "print('Gaussian Naive Bayes- ',x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Models\n",
      "Linear SVC model-  0.9722222222222222\n",
      "Multinomial Naive Bayes-  0.9722222222222222\n",
      "Gaussian Naive Bayes-  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "x1=model1.score(test_matrix,test_labels)\n",
    "x2=model2.score(test_matrix,test_labels)\n",
    "x3=clf.score(test_matrix,test_labels)\n",
    "print('Accuracy of Models')\n",
    "print('Linear SVC model- ',x1)\n",
    "print('Multinomial Naive Bayes- ',x2)\n",
    "print('Gaussian Naive Bayes- ',x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal elements represents the correctly identified(a.k.a. true identification) mails where as non-diagonal elements represents wrong classification (false identification) of mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Models\n",
      "Linear SVC model- \n",
      " [[226   4]\n",
      " [  6 124]]\n",
      "Multinomial Naive Bayes- \n",
      " [[229   1]\n",
      " [  9 121]]\n",
      "Gaussian Naive Bayes- \n",
      " [[228   2]\n",
      " [ 10 120]]\n"
     ]
    }
   ],
   "source": [
    "result3 =clf.predict(test_matrix)\n",
    "print('Confusion Matrix of Models')\n",
    "print('Linear SVC model- \\n',confusion_matrix(test_labels,result1))\n",
    "print('Multinomial Naive Bayes- \\n',confusion_matrix(test_labels,result2))\n",
    "print('Gaussian Naive Bayes- \\n',confusion_matrix(test_labels,result3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score\n",
      "Linear SVC model : 0.99%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "score1 = model1.decision_function(test_matrix)\n",
    "average_precision1 = average_precision_score(test_labels, score1)\n",
    "\n",
    "\n",
    "print('Average precision-recall score')\n",
    "print('Linear SVC model : {0:0.2f}%'.format(\n",
    "      average_precision1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfl=confusion_matrix(test_labels,result1)\n",
    "cfm=confusion_matrix(test_labels,result2)\n",
    "cfg=confusion_matrix(test_labels,result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec(x):\n",
    "    return x[1][1]/(x[1][1]+x[0][1])\n",
    "def rec(x):\n",
    "    return x[1][1]/(x[1][1]+x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Recall score\n",
      "Linear SVC model : Precision- 96.88%  Recall- 95.38%\n",
      "Multinomial Naive Bayes model : Precision- 99.18%  Recall- 93.08%\n",
      "Gaussian Naive Bayes model : Precision- 98.36%  Recall- 92.31%\n"
     ]
    }
   ],
   "source": [
    "print('Precision-Recall score')\n",
    "print('Linear SVC model : Precision- {0:0.2f}%'.format(\n",
    "      prec(cfl)*100),' Recall- {0:0.2f}%'.format(\n",
    "      rec(cfl)*100))\n",
    "print('Multinomial Naive Bayes model : Precision- {0:0.2f}%'.format(\n",
    "      prec(cfm)*100),' Recall- {0:0.2f}%'.format(\n",
    "      rec(cfm)*100))\n",
    "print('Gaussian Naive Bayes model : Precision- {0:0.2f}%'.format(\n",
    "      prec(cfg)*100),' Recall- {0:0.2f}%'.format(\n",
    "      rec(cfg)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       230\n",
      "         1.0       0.97      0.95      0.96       130\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       230\n",
      "         1.0       0.99      0.93      0.96       130\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       360\n",
      "   macro avg       0.98      0.96      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97       230\n",
      "         1.0       0.98      0.92      0.95       130\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       360\n",
      "   macro avg       0.97      0.96      0.96       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the training data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "print('Linear SVC model')\n",
    "print(classification_report(test_labels,result1 ))\n",
    "print('Multinomial Naive Bayes')\n",
    "print(classification_report(test_labels,result2 ))\n",
    "print('Gaussian Naive Bayes')\n",
    "print(classification_report(test_labels,result3 ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
